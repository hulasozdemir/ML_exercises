{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the pictures are showing the subject in similar way. To prevent the model from overfitting we need to apply a random transformation to each picture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rotation_range=40, #randomly rotate picture within [0-40] degrees\n",
    "                            width_shift_range = 0.2, # Translate picture horizontally within [0, 0.2] is the fraction of the the original image width\n",
    "                            height_shift_range = 0.2, # Translate picture vertically within [0, 0.2] is the fraction of the the original image width\n",
    "                            rescale = 1/255, # Originally RGB values are within [0-255], rescale the data so that each data point is between 0 and 1. \n",
    "                            shear_range = 0.2, # Apply a shear transformation. ie __        ___\n",
    "                                               #                                 |__| ---> /__/\n",
    "                            zoom_range = 0.2, # Zoom randomly within the given range\n",
    "                            horizontal_flip = True, # Flip half of the image randomly\n",
    "                            fill_mode = 'nearest') # After the transformation some pixel will be empty. This option\n",
    "                                                    # specifies what method should be used to fill those empty pixels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load an image and convert it into a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = load_img('dogs-vs-cats/train/cats/cat.1000.jpg')\n",
    "imgArray = img_to_array(img) # Convert image into a tensor\n",
    "imgArray = imgArray.reshape((1,) + imgArray.shape) # (1, 3, 150, 150) Add another dimension (I couldn't understand this part)\n",
    "                                            # maybe for classification purposes. \n",
    "                                            # This is a requirement for .flow()!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the random transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 0\n",
    "for batch in datagen.flow(imgArray, \n",
    "                          batch_size = 1, # Using one transformation at a time.\n",
    "                          save_to_dir = '/Users/uozdemir/iCloud Drive (Archive) - 1/Documents/GitHub/ULAS_OZDEMIR_AQM2020/Assignments/Week13/dogs-vs-cats/preview',\n",
    "                          save_prefix = 'cat', \n",
    "                          save_format = 'jpeg'):\n",
    "    n = n + 1\n",
    "    if n >= 20: # Generate 20 transformed images\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the convNet. There are 3 layers of convolution layers with RELU activation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3,3), input_shape = (150, 150, 3))) #Using 32 filters with 3x3 kernel size. Size of the images are 150x150.\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2,2))) # Each pool size is 2x2. This is used to reduce the dimension of the output.\n",
    "\n",
    "model.add(Conv2D(32, (3,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "\n",
    "model.add(Conv2D(64, (3,3))) # The example uses 64 filters\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2,2))) \n",
    "# Outputs will be a 3D feature map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten()) # Convert 3D matrix into 1D vectors\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', # This is a binary classification problem. Cross entropy is a suitable loss function.\n",
    "              optimizer='rmsprop', #?\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 800 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 400\n",
    "\n",
    "train_datagen = ImageDataGenerator( # Generate training images\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1./255) #Matrix elements are from 0-255. Scale elements so that they are within [0-1 range]\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'dogs-vs-cats/train',  # Target directory. Note that the code is looking for subfolders in train/ folder\n",
    "        target_size=(150, 150),  # All images are 150x150\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')  # This is a binary classification.\n",
    "\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory( # Create validation genenerator by using similar settings\n",
    "        'dogs-vs-cats/validation', #The code looks for a subfolders of validation/\n",
    "        target_size=(150, 150),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5/5 [==============================] - 31s 6s/step - loss: 0.6875 - accuracy: 0.6065 - val_loss: 0.6928 - val_accuracy: 0.5000\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 27s 5s/step - loss: 0.6876 - accuracy: 0.5655 - val_loss: 0.6657 - val_accuracy: 0.6450\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 27s 5s/step - loss: 0.6862 - accuracy: 0.5620 - val_loss: 0.6727 - val_accuracy: 0.6100\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 26s 5s/step - loss: 0.6710 - accuracy: 0.5815 - val_loss: 0.6581 - val_accuracy: 0.5475\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 27s 5s/step - loss: 0.6898 - accuracy: 0.5635 - val_loss: 0.6646 - val_accuracy: 0.6325\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 27s 5s/step - loss: 0.6873 - accuracy: 0.6115 - val_loss: 0.6708 - val_accuracy: 0.6650\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 27s 5s/step - loss: 0.6705 - accuracy: 0.6055 - val_loss: 0.6723 - val_accuracy: 0.5612\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 27s 5s/step - loss: 0.6602 - accuracy: 0.5865 - val_loss: 0.6298 - val_accuracy: 0.6550\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 27s 5s/step - loss: 0.6427 - accuracy: 0.6425 - val_loss: 0.6481 - val_accuracy: 0.6025\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 27s 5s/step - loss: 0.6319 - accuracy: 0.6455 - val_loss: 0.6748 - val_accuracy: 0.5950\n"
     ]
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=2000 // batch_size,\n",
    "        epochs=10,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=800 // batch_size)\n",
    "model.save_weights('first_try.h5')  # save weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got 78% accuracy with only 10 epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Bottleneck Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "generator = datagen.flow_from_directory(\n",
    "        'dogs-vs-cats/train',\n",
    "        target_size = (150, 150),\n",
    "        batch_size = batch_size,\n",
    "        class_mode = None,  # No labels. Only batches of data will be used. Since the data is already ordered.\n",
    "                        # There should be no mixing between batches\n",
    "        shuffle = False)  # Data is ordered.\n",
    "# save the output as a Numpy array\n",
    "bottleneck_features_train = model.predict_generator(generator, 2000)\n",
    "\n",
    "np.save(open('bottleneck_features_train.npy', 'wb'), bottleneck_features_train)\n",
    "\n",
    "generator = datagen.flow_from_directory(\n",
    "        'dogs-vs-cats/validation',\n",
    "        target_size = (150, 150),\n",
    "        batch_size = batch_size,\n",
    "        class_mode = None,\n",
    "        shuffle = False)\n",
    "bottleneck_features_validation = model.predict_generator(generator, 800)\n",
    "np.save(open('bottleneck_features_validation.npy', 'wb'), bottleneck_features_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32000,) (32000, 1)\n",
      "Train on 32000 samples, validate on 12800 samples\n",
      "Epoch 1/10\n",
      "32000/32000 [==============================] - 2s 67us/step - loss: 0.6936 - accuracy: 0.5016 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 2/10\n",
      "32000/32000 [==============================] - 2s 62us/step - loss: 0.6937 - accuracy: 0.4975 - val_loss: 0.6934 - val_accuracy: 0.5000\n",
      "Epoch 3/10\n",
      "32000/32000 [==============================] - 2s 62us/step - loss: 0.6934 - accuracy: 0.5018 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 4/10\n",
      "32000/32000 [==============================] - 2s 62us/step - loss: 0.6935 - accuracy: 0.4977 - val_loss: 0.6936 - val_accuracy: 0.5000\n",
      "Epoch 5/10\n",
      "32000/32000 [==============================] - 2s 62us/step - loss: 0.6933 - accuracy: 0.4989 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 6/10\n",
      "32000/32000 [==============================] - 2s 62us/step - loss: 0.6934 - accuracy: 0.4932 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 7/10\n",
      "32000/32000 [==============================] - 2s 62us/step - loss: 0.6933 - accuracy: 0.4964 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 8/10\n",
      "32000/32000 [==============================] - 2s 62us/step - loss: 0.6932 - accuracy: 0.4996 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 9/10\n",
      "32000/32000 [==============================] - 2s 62us/step - loss: 0.6933 - accuracy: 0.4984 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 10/10\n",
      "32000/32000 [==============================] - 2s 63us/step - loss: 0.6932 - accuracy: 0.5004 - val_loss: 0.6932 - val_accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "train_data = np.load(open('bottleneck_features_train.npy','rb'))\n",
    "# the features were saved in order, so recreating the labels is easy\n",
    "train_labels = np.array([0] * 16000 + [1] * 16000)\n",
    "print(train_labels.shape,train_data.shape)\n",
    "validation_data = np.load(open('bottleneck_features_validation.npy','rb'))\n",
    "validation_labels = np.array([0] * 6400 + [1] * 6400)\n",
    "model = Sequential()\n",
    "# model.add(Flatten(input_shape=train_data.shape[1:]))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_data, train_labels,\n",
    "          epochs=10,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(validation_data, validation_labels))\n",
    "model.save_weights('bottleneck_fc_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
