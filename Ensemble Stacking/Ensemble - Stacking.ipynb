{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Import some helpful packages\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Import different learners\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "# Import meta classifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data, remove rows with NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('BreastCancer.csv')\n",
    "data = data[np.logical_not(np.isnan(data))]\n",
    "data = data[~np.isnan(data).any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Shuffle the data set. \n",
    "* Then assign the features and the classes into different matrices. \n",
    "* The first column is an ID number for each observation, therefore it is ignored.\n",
    "* Replaced 0s in Y with -1s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = shuffle(data)\n",
    "X = data.iloc[:,1:-1].values\n",
    "y = data.iloc[:,-1].values\n",
    "y[y==0] = -1;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaled the feature set, and split into training (80%) and test set(20%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y[:, None]\n",
    "X_scaled = X\n",
    "X_scaled = (X_scaled - X_scaled.mean(axis=0))/X_scaled.std(axis=0)\n",
    "\n",
    "X_train, X_testMeta, y_train, y_testMeta = train_test_split(X_scaled, y, test_size=0.2)\n",
    "X_trainBase, X_testBase, y_trainBase, y_testBase = train_test_split(X_train, y_train, test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In the first layer there will be three models.\n",
    "* SVM\n",
    "* Random Forest\n",
    "* LDA-QDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_init = svm.SVC()\n",
    "svm_init.fit(X_trainBase, y_trainBase.ravel())\n",
    "yPredSVM = svm_init.predict(X_testBase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomForest_init = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "randomForest_init.fit(X_trainBase, y_trainBase.ravel())\n",
    "yPredRF = randomForest_init.predict(X_testBase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "LDA_init = LinearDiscriminantAnalysis()\n",
    "LDA_init.fit(X_trainBase, y_trainBase.ravel())\n",
    "yPredLDA = LDA_init.predict(X_testBase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "yMeta = np.vstack([yPredSVM, yPredRF, yPredLDA])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I choosed Logistic Regression Classifier as my meta model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "yStackedPredict = LogisticRegression(random_state=0).fit(yMeta.T, y_testBase.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "yPredSVMTest = svm_init.predict(X_testMeta)\n",
    "yPredRFTest = randomForest_init.predict(X_testMeta)\n",
    "yPredLDATest = LDA_init.predict(X_testMeta)\n",
    "yMetaTest = np.vstack([yPredSVMTest, yPredRFTest, yPredLDATest])\n",
    "\n",
    "yStackedPredictions = yStackedPredict.predict(yMetaTest.T)\n",
    "stackedAcc = accuracy_score(y_testMeta.ravel(), yStackedPredictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I got 96.4% accuracy with stacking. Now compare this with base model accuracies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " SVM Accuracy:  0.9416058394160584 \n",
      " Random Forest Accuracy:  0.9562043795620438 \n",
      " LDA Accuracy:  0.9343065693430657\n",
      "Stacked Model Accuracy:  0.9635036496350365\n"
     ]
    }
   ],
   "source": [
    "SVMAccuracy = accuracy_score(y_testMeta.ravel(), yPredSVMTest)\n",
    "RFAccuracy = accuracy_score(y_testMeta.ravel(), yPredRFTest)\n",
    "LDAAccuracy = accuracy_score(y_testMeta.ravel(), yPredLDATest)\n",
    "print('\\n SVM Accuracy: ',SVMAccuracy, '\\n Random Forest Accuracy: ', RFAccuracy, '\\n LDA Accuracy: ',LDAAccuracy)\n",
    "\n",
    "print('Stacked Model Accuracy: ', stackedAcc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble stacking has the highest accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
